{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d221da9",
   "metadata": {},
   "source": [
    "# Compute monthly SIC fields from OSI SAF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f878704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from dateutil import rrule, relativedelta\n",
    "import uuid\n",
    "from copy import copy\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d75b0",
   "metadata": {},
   "source": [
    "The cell below holds all the user-provided variables needed for running the task, whether the notebook is run from the web browser or called from command line via papermill (https://papermill.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "Needed parameters:\n",
    "* date : any day in the month we want to compute monthly SIC for (type: 'YYYYMM', 'YYYYMMDD', or a datetime.date object)\n",
    "* area : hemisphere (type: 'nh' or 'sh')\n",
    "* outdir : where to write the monthly file. Must exist. (type: str)\n",
    "\n",
    "```{note}\n",
    "All parameters must be set in the cell below, so that we can control the execution via papermill\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efd1b45",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dt = date(2012,7,12)\n",
    "area = 'nh'\n",
    "outdir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10246108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle datestring format and conversion\n",
    "if not isinstance(dt, date):\n",
    "    if isinstance(dt,str):\n",
    "        if len(dt) == 6:\n",
    "            dt += '16'\n",
    "        if len(dt) != 8:\n",
    "            raise ValueError(\"Datestring should br YYYYMM or YYYYMMDD\")\n",
    "        try:\n",
    "            yyyy,mm,dd = int(dt[:4]),int(dt[4:6]),int(dt[6:8])\n",
    "            dt = date(yyyy,mm,dd)\n",
    "        except Exception:\n",
    "            raise ValueError('Invalid datestring {}'.format(dt))\n",
    "\n",
    "# check area parameter\n",
    "if area not in ('nh', 'sh'):\n",
    "    raise ValueError('Invalid hemisphere (area={})'.format(area))\n",
    "    \n",
    "# check outdir exists\n",
    "if not os.path.exists(outdir):\n",
    "    raise ValueError('Output directory does not exist ({})'.format(outdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28934ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure where to find the daily SIC files, and where to write the monthly SIC file\n",
    "\n",
    "# input daily SIC files\n",
    "fn_patt = 'ice_conc_{a:}_ease2-250_{c:}_{d:%Y%m%d}1200.nc'\n",
    "sources = {'cdr':('https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/',\n",
    "                'cdr-v3p0'),\n",
    "            'icdr':('https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_cra_files/',\n",
    "                'icdr-v3p0'),\n",
    "            'icdrft':('https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_cra_files/',\n",
    "                'icdrft-v3p0')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733be5ad",
   "metadata": {},
   "source": [
    "### Find all SIC files for a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e47af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207011200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207021200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207031200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207041200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207051200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207061200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207071200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207081200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207091200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207101200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207111200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207121200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207131200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207141200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207151200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207161200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207171200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207181200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207191200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207201200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207211200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207221200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207231200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207241200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207251200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207261200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207271200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207281200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207291200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207301200.nc', 'https://thredds.met.no/thredds/dodsC/osisaf/met.no/reprocessed/ice/conc_450a_files/2012/07/ice_conc_nh_ease2-250_cdr-v3p0_201207311200.nc']\n",
      "['cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr', 'cdr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_first_last_date(dt):\n",
    "    first_day = date(dt.year,dt.month,1)\n",
    "    last_day = first_day + relativedelta.relativedelta(months=1)-timedelta(days=1)\n",
    "    return first_day, last_day\n",
    "\n",
    "def find_sic_files(dt, area):\n",
    "\n",
    "    files = []\n",
    "    srcs = []\n",
    "    # iterate over all days in the month\n",
    "    first_day, last_day = get_first_last_date(dt)\n",
    "    for d in rrule.rrule(rrule.DAILY, dtstart=first_day,\n",
    "                                        until=last_day):\n",
    "        # find the path/url to the file. There are precedence rules for what type of files\n",
    "        #   to select.\n",
    "        found_one_file = False\n",
    "        for cdr in sources.keys():\n",
    "            fn = fn_patt.format(a=area, d=d, c=sources[cdr][1])\n",
    "            fn = os.path.join(sources[cdr][0],'{:%Y/%m/}'.format(d),fn)\n",
    "            try:\n",
    "                # this url exists, append it and move to next date\n",
    "                ds = xr.open_dataset(fn)\n",
    "                found_one_file = True\n",
    "                files.append(fn)\n",
    "                srcs.append(cdr)\n",
    "                continue\n",
    "            except OSError:\n",
    "                # no valid file at this url, check the next rule\n",
    "                pass\n",
    "        \n",
    "        # no file found. Add a warning (but we can continue)\n",
    "        if not found_one_file:\n",
    "            print(\"WARNING: could not find OSI SAF SIC v3 file for {} {}\".format(area, d.date()))\n",
    "        \n",
    "    return files, srcs\n",
    "\n",
    "files, srcs = find_sic_files(dt, area)\n",
    "print(files)\n",
    "print(srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843df824",
   "metadata": {},
   "source": [
    "### Open access to all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa4ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                         (time: 31, nv: 2, xc: 432, yc: 432)\n",
      "Coordinates:\n",
      "  * time                            (time) datetime64[ns] 2012-07-01T12:00:00...\n",
      "  * xc                              (xc) float64 -5.388e+03 ... 5.388e+03\n",
      "  * yc                              (yc) float64 5.388e+03 ... -5.388e+03\n",
      "    lat                             (yc, xc) float32 dask.array<chunksize=(432, 432), meta=np.ndarray>\n",
      "    lon                             (yc, xc) float32 dask.array<chunksize=(432, 432), meta=np.ndarray>\n",
      "Dimensions without coordinates: nv\n",
      "Data variables:\n",
      "    Lambert_Azimuthal_Grid          (time) int32 -2147483647 ... -2147483647\n",
      "    time_bnds                       (time, nv) datetime64[ns] dask.array<chunksize=(1, 2), meta=np.ndarray>\n",
      "    ice_conc                        (time, yc, xc) float64 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "    raw_ice_conc_values             (time, yc, xc) float64 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "    total_standard_uncertainty      (time, yc, xc) float64 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "    smearing_standard_uncertainty   (time, yc, xc) float64 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "    algorithm_standard_uncertainty  (time, yc, xc) float64 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "    status_flag                     (time, yc, xc) float32 dask.array<chunksize=(1, 432, 432), meta=np.ndarray>\n",
      "Attributes: (12/43)\n",
      "    title:                           Sea Ice Concentration Climate Data Recor...\n",
      "    summary:                         This climate data record of sea ice conc...\n",
      "    topiccategory:                   Oceans ClimatologyMeteorologyAtmosphere\n",
      "    geospatial_lat_min:              16.62393\n",
      "    geospatial_lat_max:              90.0\n",
      "    geospatial_lon_min:              -180.0\n",
      "    ...                              ...\n",
      "    keywords:                        GCMDSK:Earth Science > Cryosphere > Sea ...\n",
      "    keywords_vocabulary:             GCMDSK:GCMD Science Keywords:https://gcm...\n",
      "    Conventions:                     CF-1.7,ACDD-1.3\n",
      "    algorithm:                       SICCI3LF (19V, 37V, 37H)\n",
      "    source:                          FCDR of SMMR / SSMI / SSMIS Brightness T...\n",
      "    DODS_EXTRA.Unlimited_Dimension:  time\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_mfdataset(files,)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682dcadd",
   "metadata": {},
   "source": [
    "### Compute monthly average SIC\n",
    "\n",
    "This requires re-combining the filtered SIC in 'ice_conc' with the unfiltered values in 'raw_ice_conc_values'. We use the 'status_flag' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_conc = ds['ice_conc'].to_masked_array()\n",
    "raw_ice_conc_values = ds['raw_ice_conc_values'].to_masked_array()\n",
    "status_flag = ds['status_flag'].to_masked_array().astype('short')\n",
    "\n",
    "# combine ice_conc with raw_ice_conc_values using the status_flag\n",
    "ice_conc[ice_conc==100] = raw_ice_conc_values[ice_conc==100]\n",
    "ice_conc[(status_flag & 4) == 4] = raw_ice_conc_values[(status_flag & 4) == 4]\n",
    "\n",
    "# re-enter daily ice_conc into the xarray dataset\n",
    "ds['ice_conc'][:] = ice_conc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebc2c1",
   "metadata": {},
   "source": [
    "Use xarray to compute the mean over time (now that we replaced the ice_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd86c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_month = ds.mean(dim=\"time\", keep_attrs=True)\n",
    "ds_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52eb20",
   "metadata": {},
   "source": [
    "Re-arrange SIC values into 'ice_conc' and 'raw_ice_conc_values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_conc = ds_month['ice_conc'].to_masked_array()\n",
    "raw_ice_conc_values = np.ma.array(np.zeros_like(ice_conc).astype(ice_conc.dtype),\n",
    "                                  mask=np.ones_like(ice_conc).astype('bool'))\n",
    "index = ice_conc>100\n",
    "raw_ice_conc_values[index] = ice_conc[index]\n",
    "ice_conc[index] = 100\n",
    "\n",
    "owf = ice_conc<10\n",
    "raw_ice_conc_values[owf] = ice_conc[owf]\n",
    "ice_conc[owf] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08846f8",
   "metadata": {},
   "source": [
    "Prepare a simplified 'status_flag' variable. We only keep '1' (land) and '128' (climatology). The rest we set to '0' (nominal) of '4' (open water filter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_flag = ds['status_flag'][0].to_masked_array().astype('short')\n",
    "index = (status_flag != 1)*(status_flag != 128)\n",
    "status_flag[index] = 0\n",
    "\n",
    "# empty 'raw_ice_conc_values' over climatology (as in the daily files)\n",
    "raw_ice_conc_values[status_flag == 128] = np.ma.masked\n",
    "\n",
    "# store '4' (OWF) in the status_flag where we have raw_ice_conc_values over water (SIC < 10%)\n",
    "status_flag[owf*(status_flag != 128)] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38324586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store monthly mean ice_conc, raw_ice_conc_values, and status_flags back in the xarray structure\n",
    "ds_month['raw_ice_conc_values'][:] = raw_ice_conc_values\n",
    "ds_month['ice_conc'][:] = ice_conc\n",
    "ds_month['status_flag'][:] = status_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f217552",
   "metadata": {},
   "source": [
    "### Clean the xarray dataset structure and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_month = ds_month.drop_vars( ('total_standard_uncertainty', 'smearing_standard_uncertainty', 'algorithm_standard_uncertainty',) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf810ec",
   "metadata": {},
   "source": [
    "The filename should reflect what type of daily SIC files were used as input. If only 'cdr' files were used, the monthly file should have 'cdr'. If only 'icdr' files were used, the monthly files should have 'icdr'. If some fast-track ICDR files ('icdrft') were used, this should also be in the name of the monthly file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf47af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Amend some attributes\n",
    "first_day, last_day = get_first_last_date(dt)\n",
    "ds_month.attrs['time_coverage_start'] = datetime.combine(first_day, time()).isoformat()+'Z'\n",
    "ds_month.attrs['time_coverage_end'] = (datetime.combine(last_day,time())+timedelta(days=1)).isoformat()+'Z'\n",
    "\n",
    "ds_month.attrs['time_coverage_duration'] = 'P1M'\n",
    "ds_month.attrs['time_coverage_resolution'] = 'P1M'\n",
    "\n",
    "now = datetime.utcnow().replace(microsecond=0)\n",
    "ds_month.attrs['history'] = now.isoformat()+'Z' + ' creation'\n",
    "ds_month.attrs['date_created'] = now.date().isoformat()\n",
    "\n",
    "ds_month.attrs['tracking_id'] = str(uuid.uuid4())\n",
    "\n",
    "ds_month.attrs['title'] = 'Monthly ' + ds_month.attrs['title']\n",
    "\n",
    "# Development/Demonstration phase: remove DOI and product_status\n",
    "try:\n",
    "    del ds_month.attrs['doi']\n",
    "    del ds_month.attrs['naming_authority']\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "ds_month.attrs['product_version'] += ' beta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b5fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open one of the original files to extract information like dtype, _FillValue, time units, etc...\n",
    "dso = xr.open_dataset(files[0],mask_and_scale=False,decode_times=False)\n",
    "dso\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd2aab",
   "metadata": {},
   "source": [
    "Add 'time' dimension and coordinate variable (the 16th of the month).\n",
    "\n",
    "In addition, add the 'time_bnds' variable, which requires the 'nv' dimension. time_bnds[0] gets the first day of the month (0 utc), time_bnds[1] gets the first day of the following month (0 utc).\n",
    "\n",
    "This turned out to be a bit messy, suggestions for improvements are welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b032b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the time_bnds variable [start, end] and it as a data variable to the dataset.\n",
    "time_bnds = [np.datetime64(ds_month.attrs['time_coverage_start'][:-1]),np.datetime64(ds_month.attrs['time_coverage_end'][:-1])]\n",
    "time_bnds_da = xr.DataArray(time_bnds, [('nv', time_bnds,)])\n",
    "\n",
    "# For some reasons, ds.assign brings a coordinate variable 'nv' that we must remove.\n",
    "ds_month = ds_month.assign(time_bnds=time_bnds_da)\n",
    "ds_month = ds_month.drop(labels='nv')\n",
    "ds_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the time coordinate\n",
    "mid_time = [np.datetime64('{:%Y-%m-16 12:00:00}'.format(dt)),]\n",
    "mid_time_da = xr.DataArray(mid_time, [('time', mid_time,)])\n",
    "\n",
    "mid_time_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21246e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add the 'time' coordinate variable (and dimension) to the dataset object\n",
    "dst_month = ds_month.expand_dims(time=mid_time_da)\n",
    "\n",
    "# drop time dimension for the CRS (added by expand_dims)\n",
    "dst_month['Lambert_Azimuthal_Grid'] = dst_month['Lambert_Azimuthal_Grid'].squeeze(dim='time',drop=True)\n",
    "\n",
    "# assign original attributes, but not 'units' nor 'calendar' as these\n",
    "#   are re-introduced by xarray as encoding (not attributes) at time of\n",
    "#   writing to netCDF\n",
    "time_attrs = copy(dso.time.attrs)\n",
    "time_attrs.pop('units',None)\n",
    "time_attrs.pop('calendar',None)\n",
    "for k in list(time_attrs.keys()):\n",
    "    if k.startswith('_'):\n",
    "        time_attrs.pop(k, None)\n",
    "dst_month.time.attrs = time_attrs\n",
    "dst_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqued list of daily CDR sources\n",
    "srcs = sorted(list(set(srcs)))\n",
    "\n",
    "# monthly file name (note the format of the datestring: YYYYMM.nc)\n",
    "fn_patt = 'ice_conc_{a:}_ease2-250_{c:}-v3p0_{d:%Y%m}.nc'\n",
    "fn = fn_patt.format(a=area, d=dt, c=srcs[-1])\n",
    "fn = os.path.join(outdir,fn)\n",
    "\n",
    "# encoding\n",
    "encoding = {'time': {'dtype':dso['time'].dtype, 'units':dso['time'].units, 'calendar':dso['time'].calendar,'_FillValue':None},\n",
    "            'time_bnds': {'dtype':dso['time_bnds'].dtype,'units':dso['time_bnds'].units,'_FillValue':None},\n",
    "            'ice_conc': {'dtype':dso['ice_conc'].dtype, 'scale_factor':dso['ice_conc'].scale_factor, '_FillValue':dso['ice_conc']._FillValue},\n",
    "            'raw_ice_conc_values': {'dtype':dso['raw_ice_conc_values'].dtype, 'scale_factor':dso['raw_ice_conc_values'].scale_factor, '_FillValue':dso['raw_ice_conc_values']._FillValue},\n",
    "            'status_flag': {'dtype':dso['status_flag'].dtype, '_FillValue':dso['status_flag']._FillValue},\n",
    "            'lat': {'_FillValue':None}, 'lon': {'_FillValue':None},\n",
    "            'xc': {'_FillValue':None}, 'yc': {'_FillValue':None},\n",
    "            'Lambert_Azimuthal_Grid': {'_FillValue':None, 'dtype':dso['Lambert_Azimuthal_Grid'].dtype}\n",
    "           }\n",
    "\n",
    "for v in encoding.keys():\n",
    "    encoding[v]['zlib']=True\n",
    "\n",
    "# save the monthly xarray dataset to file\n",
    "if os.path.exists(fn):\n",
    "    os.remove(fn)\n",
    "dst_month.to_netcdf(fn, encoding=encoding, format=\"NETCDF4_CLASSIC\")\n",
    "\n",
    "print(fn + ' ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045cdac",
   "metadata": {},
   "source": [
    "## Re-open and plot the content of the file for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbaa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(fn)\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.imshow(ds['ice_conc'][0], interpolation='none')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Monthly {} {}'.format(np.datetime_as_string(ds['time'].data[0],unit='M'), ds.product_id.upper()))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "sflags = [0,1,4,128,]\n",
    "fig, axs = plt.subplots(2,2,figsize=(10,10))\n",
    "for isf, sf in enumerate(sflags):\n",
    "    i,j = np.unravel_index(isf, axs.shape)\n",
    "    axs[i,j].imshow(ds['status_flag'][0]==sf, interpolation='none')\n",
    "    axs[i,j].set_title('status_flag == {}'.format(sf))\n",
    "    axs[i,j].set_xticks([])\n",
    "    axs[i,j].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d836e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
